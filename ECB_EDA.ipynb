{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECB EDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtCcmbD27PEOqHkDDNuICV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalopey/coreference/blob/main/ECB_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz9sIB7EWuGL"
      },
      "source": [
        "# **<font color=\"darkred\">ECB+ EDA</font>**\n",
        "\n",
        "#### **Authors:**\n",
        "Eduardo Peynetti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWmXHDbeXQM0"
      },
      "source": [
        "## **<font color=\"darkred\">Setup Notebook</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQHVfKZPMj_m"
      },
      "source": [
        "#### Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3XrtYLIMjaT",
        "outputId": "b7fdae35-7d6a-40a4-9a5c-f12409547b19"
      },
      "source": [
        "!pip install xmltodict"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n",
            "Collecting mendelai-brat-parser\n",
            "  Downloading mendelai_brat_parser-0.0.4-py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: mendelai-brat-parser\n",
            "Successfully installed mendelai-brat-parser-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W02sQw8JMqJz"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bJwpGISJqzL"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import tarfile\n",
        "import xmltodict\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnfnFg7QMviV"
      },
      "source": [
        "#### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvXhaSa1GTnG"
      },
      "source": [
        "def download_file(packet_url, base_path=\"\", extract=False, headers=None):\n",
        "  if base_path != \"\":\n",
        "    if not os.path.exists(base_path):\n",
        "      os.mkdir(base_path)\n",
        "  packet_file = os.path.basename(packet_url)\n",
        "  with requests.get(packet_url, stream=True, headers=headers) as r:\n",
        "      r.raise_for_status()\n",
        "      with open(os.path.join(base_path,packet_file), 'wb') as f:\n",
        "          for chunk in r.iter_content(chunk_size=8192):\n",
        "              f.write(chunk)\n",
        "  \n",
        "  if extract:\n",
        "    if packet_file.endswith('.zip'):\n",
        "      with zipfile.ZipFile(os.path.join(base_path,packet_file)) as zfile:\n",
        "        zfile.extractall(base_path)\n",
        "    else:\n",
        "      packet_name = packet_file.split('.')[0]\n",
        "      with tarfile.open(os.path.join(base_path,packet_file)) as tfile:\n",
        "        tfile.extractall(base_path)\n",
        "\n",
        "def unpack_ecb(base_path='datasets'):\n",
        "  ecb_dir = 'ECB+_LREC2014'\n",
        "  ecb_file = 'ECB+.zip'\n",
        "  with zipfile.ZipFile(os.path.join(base_path,ecb_dir,ecb_file)) as zfile:\n",
        "    zfile.extractall(os.path.join(base_path,ecb_dir))\n",
        "\n",
        "\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(width=80) \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErTtO54JM4BW"
      },
      "source": [
        "## **<font color=\"darkred\">Download Datasets</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jfTOsMPJPdH"
      },
      "source": [
        "ECB_PATH = 'datasets/ECB+_LREC2014/ECB+'\n",
        "LITBANK_PATH = 'datasets/litbank-master'\n",
        "WIKI_PATH = 'datasets/WikiCoref'\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DHujh9YGd0w"
      },
      "source": [
        "download_file('http://kyoto.let.vu.nl/repo/ECB+_LREC2014.zip', base_path=\"datasets\", extract=True)\n",
        "unpack_ecb(base_path=\"datasets\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyR9wez3L5eA"
      },
      "source": [
        "## **<font color=\"darkred\">ECB+</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihwiCc2fPrUe"
      },
      "source": [
        "http://www.newsreader-project.eu/results/data/the-ecb-corpus/\n",
        "\n",
        "http://www.newsreader-project.eu/files/2013/01/NWR-2014-1.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "UUPwr-1LJAZP",
        "outputId": "bcec97b1-575f-4b89-a3a5-7c25f109324a"
      },
      "source": [
        "file = os.path.join(ECB_PATH, '1', '1_1ecbplus.xml')\n",
        "\n",
        "with open(file,'rb') as f:\n",
        "    dct = xmltodict.parse(f)\n",
        "\n",
        "print('Document keys:\\n')\n",
        "display(dct['Document'].keys())\n",
        "\n",
        "print('\\n Token data:\\n')\n",
        "display(dct['Document']['token'][0])\n",
        "\n",
        "string = ''\n",
        "\n",
        "for token in dct['Document']['token']:\n",
        "    string += token['#text'] + ' '\n",
        "\n",
        "print('\\n', wrapper.fill(string))\n",
        "\n",
        "print('\\n Markables:\\n')\n",
        "display(dct['Document']['Markables'].keys())\n",
        "\n",
        "print('\\n Relations:\\n')\n",
        "\n",
        "dct['Document']['Relations']['CROSS_DOC_COREF'][0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document keys:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "odict_keys(['@doc_name', '@doc_id', 'token', 'Markables', 'Relations'])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Token data:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OrderedDict([('@t_id', '1'),\n",
              "             ('@sentence', '0'),\n",
              "             ('@number', '0'),\n",
              "             ('#text', 'http')])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " http : / / www . accesshollywood . com / lindsay - lohan - leaves - betty - ford\n",
            "- checks - into - malibu - rehab _ article _ 80744 Lindsay Lohan Leaves Betty\n",
            "Ford , Checks Into Malibu Rehab First Published : June 13 , 2013 4 : 59 PM EDT\n",
            "Lindsay Lohan has left the Betty Ford Center and is moving to a rehab facility\n",
            "in Malibu , Calif . , Access Hollywood has confirmed . A spokesperson for The\n",
            "Los Angeles Superior Court confirmed to Access that a judge signed an order\n",
            "yesterday allowing the transfer to Cliffside , where she will continue with her\n",
            "90 - day court - mandated rehab . Lohan ’ s attorney , Shawn Holley , spoke out\n",
            "about the move . “ Lindsay is grateful for the treatment she received at the\n",
            "Betty Ford Center . She has completed her course of treatment there and looks\n",
            "forward to continuing her treatment and building on the foundation established\n",
            "at Betty Ford , ” Holley said in a statement to Access . The actress checked\n",
            "into the Betty Ford Center in May as part of a plea deal stemming from her June\n",
            "2012 car accident case .\n",
            "\n",
            " Markables:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "odict_keys(['ACTION_ASPECTUAL', 'ACTION_CAUSATIVE', 'ACTION_OCCURRENCE', 'ACTION_REPORTING', 'ACTION_STATE', 'HUMAN_PART_ORG', 'HUMAN_PART_PER', 'LOC_FAC', 'NON_HUMAN_PART', 'TIME_DATE', 'TIME_DURATION', 'TIME_OF_THE_DAY'])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Relations:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('@r_id', '21683'),\n",
              "             ('@note', 'ACT15736242788923354'),\n",
              "             ('source', OrderedDict([('@m_id', '34')])),\n",
              "             ('target', OrderedDict([('@m_id', '72')]))])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}